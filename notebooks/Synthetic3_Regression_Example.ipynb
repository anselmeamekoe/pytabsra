{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7439a4-6567-436d-990d-4207d24a4b7f",
   "metadata": {},
   "source": [
    "# Regression example: *Synthetic* 3 dataset\n",
    "$$y  = (5x_1-5x_2)1_{x_5\\le 0}+(5x_3-5x_4)1_{x_5> 0}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616b351-7e33-43d7-aa88-98833d2f0e39",
   "metadata": {},
   "source": [
    "## Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dbb648-dc45-47ad-828c-714357743cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8edfa94-295d-4f17-86af-612ba3a022f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4ccb8e-7a3b-4aae-8ad3-50324260645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1649cc3c-baa1-4c09-ab5f-0bccf545336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from skorch.callbacks import EarlyStopping,LRScheduler,Checkpoint, TrainEndCheckpoint, EpochScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91da571b-7fde-439e-a8d5-8bbacb6d87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabsra.skorch_tabsra import InputShapeSetterTabSRA,TabSRALinearRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff4793-e7b6-4102-ae5e-590b5be83f16",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4db921e-d6f9-4a2e-9abc-a0a6ec86f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x1 = np.random.normal(0,1,3*10000)\n",
    "x2 = np.random.normal(0,1,3*10000)\n",
    "x3 = np.random.normal(0,1,3*10000)\n",
    "x4 = np.random.normal(0,1,3*10000)\n",
    "x5 = np.random.normal(0,1,3*10000)\n",
    "X = np.concatenate((x1.reshape(-1,1), x2.reshape(-1,1),x3.reshape(-1,1),x4.reshape(-1,1),x5.reshape(-1,1)  ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671077aa-6080-4375-bb5c-8623fd911f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 7500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd = (5*x1-5*x2)*(x5<=0) + (5*x3-5*x4)*(x5>0)\n",
    "y_c = 1/(1+np.exp(-odd))\n",
    "y = np.where(y_c>0.5, 1,0)\n",
    "X_train_,X_test_,Y_train_,Y_test_ = train_test_split(X,odd,stratify =y , random_state=42)\n",
    "n_features, n_classes = 5,1\n",
    "len(Y_train_),len(Y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0762618-1974-4172-8315-f349a8764fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['x1','x2','x3','x4','x5']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfdc49-40d1-4339-b4fa-5ead95773535",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Model: TabSRALinear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56227de1-5e87-4d95-b964-8ab513604c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_loss\n",
    "other_params = {\"module__encoder_bias\":True,\n",
    "                \"module__classifier_bias\":False,\n",
    "                \"module__n_head\":1,\n",
    "                \"module__dim_head\":4,\n",
    "                \"optimizer__lr\":0.01,\n",
    "                \"max_epochs\":150,\n",
    "                \"batch_size\":512,                \n",
    "                \"optimizer__weight_decay\":0,\n",
    "                \"random_state\":42,\n",
    "               }\n",
    "scoring = EpochScoring(scoring='r2',lower_is_better=False)\n",
    "setter = InputShapeSetterTabSRA(regression=True)\n",
    "early_stop = EarlyStopping(monitor=scoring.scoring, patience=20,load_best=True,lower_is_better=False, threshold=0.00001,threshold_mode='abs')\n",
    "lr_scheduler = LRScheduler(policy=ReduceLROnPlateau, patience=15, min_lr=2e-5,factor=0.2, verbose=1, mode='max',monitor=scoring.scoring)\n",
    "call_b = [scoring, setter, early_stop, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc0acce-a2b6-4c69-90f5-4a1ed432a407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: module__dim_input, module__dim_output.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch      r2    train_loss    valid_loss      dur\n",
      "-------  ------  ------------  ------------  -------\n",
      "      1  \u001b[36m0.1471\u001b[0m       \u001b[32m47.6918\u001b[0m       \u001b[35m41.5221\u001b[0m  13.6775\n",
      "      2  \u001b[36m0.3002\u001b[0m       \u001b[32m39.1473\u001b[0m       \u001b[35m34.0702\u001b[0m  0.2457\n",
      "      3  \u001b[36m0.4785\u001b[0m       \u001b[32m30.9727\u001b[0m       \u001b[35m25.3871\u001b[0m  0.2001\n",
      "      4  \u001b[36m0.5967\u001b[0m       \u001b[32m23.2003\u001b[0m       \u001b[35m19.6363\u001b[0m  0.2089\n",
      "      5  \u001b[36m0.6703\u001b[0m       \u001b[32m18.7371\u001b[0m       \u001b[35m16.0495\u001b[0m  0.2016\n",
      "      6  \u001b[36m0.7209\u001b[0m       \u001b[32m15.5881\u001b[0m       \u001b[35m13.5877\u001b[0m  0.2521\n",
      "      7  \u001b[36m0.7612\u001b[0m       \u001b[32m13.3134\u001b[0m       \u001b[35m11.6240\u001b[0m  0.2149\n",
      "      8  \u001b[36m0.7855\u001b[0m       \u001b[32m11.6417\u001b[0m       \u001b[35m10.4425\u001b[0m  0.1948\n",
      "      9  \u001b[36m0.8088\u001b[0m       \u001b[32m10.4440\u001b[0m        \u001b[35m9.3066\u001b[0m  0.1913\n",
      "     10  \u001b[36m0.8264\u001b[0m        \u001b[32m9.4632\u001b[0m        \u001b[35m8.4532\u001b[0m  0.1960\n",
      "     11  \u001b[36m0.8387\u001b[0m        \u001b[32m8.7079\u001b[0m        \u001b[35m7.8509\u001b[0m  0.1996\n",
      "     12  \u001b[36m0.8467\u001b[0m        \u001b[32m8.2203\u001b[0m        \u001b[35m7.4637\u001b[0m  0.1980\n",
      "     13  \u001b[36m0.8513\u001b[0m        \u001b[32m7.8352\u001b[0m        \u001b[35m7.2410\u001b[0m  0.1948\n",
      "     14  \u001b[36m0.8577\u001b[0m        \u001b[32m7.6288\u001b[0m        \u001b[35m6.9299\u001b[0m  0.1935\n",
      "     15  \u001b[36m0.8612\u001b[0m        \u001b[32m7.3704\u001b[0m        \u001b[35m6.7584\u001b[0m  0.1940\n",
      "     16  \u001b[36m0.8650\u001b[0m        \u001b[32m7.1596\u001b[0m        \u001b[35m6.5730\u001b[0m  0.1953\n",
      "     17  \u001b[36m0.8661\u001b[0m        \u001b[32m6.9558\u001b[0m        \u001b[35m6.5177\u001b[0m  0.1979\n",
      "     18  \u001b[36m0.8707\u001b[0m        \u001b[32m6.8448\u001b[0m        \u001b[35m6.2933\u001b[0m  0.2035\n",
      "     19  \u001b[36m0.8720\u001b[0m        \u001b[32m6.7632\u001b[0m        \u001b[35m6.2326\u001b[0m  0.2058\n",
      "     20  0.8710        \u001b[32m6.6636\u001b[0m        6.2814  0.1958\n",
      "     21  \u001b[36m0.8750\u001b[0m        \u001b[32m6.5772\u001b[0m        \u001b[35m6.0864\u001b[0m  0.1873\n",
      "     22  0.8747        6.6174        6.1007  0.1905\n",
      "     23  \u001b[36m0.8759\u001b[0m        \u001b[32m6.5605\u001b[0m        \u001b[35m6.0409\u001b[0m  0.1972\n",
      "     24  \u001b[36m0.8886\u001b[0m        \u001b[32m6.1385\u001b[0m        \u001b[35m5.4242\u001b[0m  0.1904\n",
      "     25  \u001b[36m0.8918\u001b[0m        \u001b[32m5.7181\u001b[0m        \u001b[35m5.2656\u001b[0m  0.1920\n",
      "     26  \u001b[36m0.8940\u001b[0m        \u001b[32m5.5785\u001b[0m        \u001b[35m5.1614\u001b[0m  0.1958\n",
      "     27  0.8928        \u001b[32m5.5199\u001b[0m        5.2201  0.1893\n",
      "     28  \u001b[36m0.8948\u001b[0m        5.5500        \u001b[35m5.1197\u001b[0m  0.1975\n",
      "     29  \u001b[36m0.9083\u001b[0m        \u001b[32m5.2441\u001b[0m        \u001b[35m4.4651\u001b[0m  0.1983\n",
      "     30  \u001b[36m0.9117\u001b[0m        \u001b[32m4.7010\u001b[0m        \u001b[35m4.2996\u001b[0m  0.1927\n",
      "     31  \u001b[36m0.9128\u001b[0m        \u001b[32m4.5956\u001b[0m        \u001b[35m4.2451\u001b[0m  0.1890\n",
      "     32  \u001b[36m0.9151\u001b[0m        \u001b[32m4.5374\u001b[0m        \u001b[35m4.1317\u001b[0m  0.1943\n",
      "     33  0.9143        \u001b[32m4.4966\u001b[0m        4.1715  0.1913\n",
      "     34  0.9147        4.6195        4.1536  0.1850\n",
      "     35  \u001b[36m0.9152\u001b[0m        \u001b[32m4.4829\u001b[0m        \u001b[35m4.1278\u001b[0m  0.1986\n",
      "     36  \u001b[36m0.9257\u001b[0m        \u001b[32m4.4247\u001b[0m        \u001b[35m3.6167\u001b[0m  0.1903\n",
      "     37  \u001b[36m0.9454\u001b[0m        \u001b[32m3.2180\u001b[0m        \u001b[35m2.6564\u001b[0m  0.1907\n",
      "     38  \u001b[36m0.9575\u001b[0m        \u001b[32m2.5174\u001b[0m        \u001b[35m2.0701\u001b[0m  0.1975\n",
      "     39  \u001b[36m0.9592\u001b[0m        \u001b[32m2.1511\u001b[0m        \u001b[35m1.9850\u001b[0m  0.1917\n",
      "     40  \u001b[36m0.9716\u001b[0m        \u001b[32m1.8761\u001b[0m        \u001b[35m1.3806\u001b[0m  0.1887\n",
      "     41  \u001b[36m0.9796\u001b[0m        \u001b[32m1.2381\u001b[0m        \u001b[35m0.9934\u001b[0m  0.1899\n",
      "     42  \u001b[36m0.9842\u001b[0m        \u001b[32m0.9766\u001b[0m        \u001b[35m0.7685\u001b[0m  0.1882\n",
      "     43  0.9831        \u001b[32m0.8347\u001b[0m        0.8239  0.1963\n",
      "     44  \u001b[36m0.9857\u001b[0m        \u001b[32m0.6822\u001b[0m        \u001b[35m0.6959\u001b[0m  0.1957\n",
      "     45  \u001b[36m0.9866\u001b[0m        \u001b[32m0.6034\u001b[0m        \u001b[35m0.6525\u001b[0m  0.2002\n",
      "     46  \u001b[36m0.9876\u001b[0m        \u001b[32m0.5973\u001b[0m        \u001b[35m0.6017\u001b[0m  0.2031\n",
      "     47  0.9858        \u001b[32m0.5695\u001b[0m        0.6931  0.2052\n",
      "     48  \u001b[36m0.9914\u001b[0m        \u001b[32m0.4813\u001b[0m        \u001b[35m0.4187\u001b[0m  0.1875\n",
      "     49  0.9892        \u001b[32m0.4799\u001b[0m        0.5255  0.1959\n",
      "     50  0.9892        0.4959        0.5254  0.1982\n",
      "     51  \u001b[36m0.9915\u001b[0m        \u001b[32m0.4117\u001b[0m        \u001b[35m0.4125\u001b[0m  0.2026\n",
      "     52  0.9872        0.5020        0.6250  0.2016\n",
      "     53  0.9874        0.6830        0.6156  0.2071\n",
      "     54  0.9905        0.5810        0.4647  0.1937\n",
      "     55  0.9899        0.4230        0.4941  0.2022\n",
      "     56  \u001b[36m0.9917\u001b[0m        0.4147        \u001b[35m0.4022\u001b[0m  0.2082\n",
      "     57  0.9890        \u001b[32m0.3886\u001b[0m        0.5336  0.2038\n",
      "     58  0.9872        \u001b[32m0.3591\u001b[0m        0.6220  0.2054\n",
      "     59  0.9904        0.4864        0.4684  0.2118\n",
      "     60  0.9906        0.4631        0.4573  0.1999\n",
      "     61  \u001b[36m0.9922\u001b[0m        0.3998        \u001b[35m0.3818\u001b[0m  0.1866\n",
      "     62  0.9906        \u001b[32m0.3364\u001b[0m        0.4577  0.1883\n",
      "     63  0.9917        \u001b[32m0.3324\u001b[0m        0.4024  0.1876\n",
      "     64  0.9921        \u001b[32m0.3060\u001b[0m        0.3841  0.1921\n",
      "     65  0.9919        0.3105        0.3966  0.1847\n",
      "     66  \u001b[36m0.9923\u001b[0m        0.3542        \u001b[35m0.3760\u001b[0m  0.1832\n",
      "     67  0.9886        0.3248        0.5538  0.1891\n",
      "     68  \u001b[36m0.9930\u001b[0m        0.3183        \u001b[35m0.3407\u001b[0m  0.1897\n",
      "     69  0.9908        \u001b[32m0.2878\u001b[0m        0.4469  0.1921\n",
      "     70  0.9895        0.3678        0.5092  0.1910\n",
      "     71  0.9919        0.3862        0.3931  0.1920\n",
      "     72  0.9914        0.3747        0.4163  0.1926\n",
      "     73  \u001b[36m0.9938\u001b[0m        0.3113        \u001b[35m0.3023\u001b[0m  0.1945\n",
      "     74  0.9909        0.3305        0.4445  0.2112\n",
      "     75  0.9903        0.2989        0.4707  0.1945\n",
      "     76  0.9927        \u001b[32m0.2621\u001b[0m        0.3543  0.1950\n",
      "     77  0.9936        \u001b[32m0.2513\u001b[0m        0.3116  0.1958\n",
      "     78  \u001b[36m0.9938\u001b[0m        0.2565        \u001b[35m0.2995\u001b[0m  0.1927\n",
      "     79  0.9938        0.2897        0.3016  0.1982\n",
      "     80  \u001b[36m0.9940\u001b[0m        \u001b[32m0.2474\u001b[0m        \u001b[35m0.2944\u001b[0m  0.1958\n",
      "     81  0.9930        \u001b[32m0.1157\u001b[0m        0.3428  0.1944\n",
      "     82  0.9936        \u001b[32m0.1042\u001b[0m        0.3127  0.1937\n",
      "     83  0.9927        0.1118        0.3535  0.1899\n",
      "     84  \u001b[36m0.9973\u001b[0m        0.1427        \u001b[35m0.1316\u001b[0m  0.1949\n",
      "     85  0.9940        0.1945        0.2909  0.1900\n",
      "     86  0.9895        \u001b[32m0.1019\u001b[0m        0.5105  0.2013\n",
      "     87  0.9936        0.1348        0.3110  0.2210\n",
      "     88  0.9952        \u001b[32m0.0759\u001b[0m        0.2330  0.1952\n",
      "     89  0.9964        \u001b[32m0.0619\u001b[0m        0.1746  0.1939\n",
      "     90  0.9949        \u001b[32m0.0596\u001b[0m        0.2503  0.1900\n",
      "     91  0.9930        0.0794        0.3423  0.2091\n",
      "     92  0.9943        0.1322        0.2798  0.1913\n",
      "     93  0.9923        0.1298        0.3761  0.2018\n",
      "     94  0.9945        0.1005        0.2657  0.1933\n",
      "     95  0.9950        0.1443        0.2429  0.1933\n",
      "     96  \u001b[36m0.9975\u001b[0m        0.0931        \u001b[35m0.1207\u001b[0m  0.2259\n",
      "     97  0.9956        0.0665        0.2123  0.1965\n",
      "     98  0.9957        0.0835        0.2104  0.1936\n",
      "     99  0.9967        \u001b[32m0.0581\u001b[0m        0.1613  0.1951\n",
      "    100  0.9950        0.1374        0.2415  0.2048\n",
      "    101  0.9929        \u001b[32m0.0456\u001b[0m        0.3464  0.2052\n",
      "    102  0.9937        \u001b[32m0.0442\u001b[0m        0.3071  0.2111\n",
      "    103  0.9947        0.0567        0.2596  0.1937\n",
      "    104  0.9943        0.0444        0.2765  0.2320\n",
      "    105  0.9899        0.1132        0.4901  0.1915\n",
      "    106  0.9957        0.1806        0.2093  0.1955\n",
      "    107  0.9934        0.1800        0.3223  0.1968\n",
      "    108  0.9972        0.1160        0.1348  0.1957\n",
      "    109  0.9955        0.0696        0.2169  0.1964\n",
      "    110  0.9961        0.0758        0.1880  0.1922\n",
      "    111  0.9940        0.0687        0.2933  0.1920\n",
      "Epoch 00112: reducing learning rate of group 0 to 2.0000e-03.\n",
      "    112  0.9968        0.0596        0.1561  0.1945\n",
      "    113  0.9955        0.0491        0.2181  0.1997\n",
      "    114  0.9956        \u001b[32m0.0268\u001b[0m        0.2125  0.2049\n",
      "    115  0.9955        \u001b[32m0.0245\u001b[0m        0.2174  0.1969\n",
      "Stopping since r2 has not improved in the last 20 epochs.\n",
      "Restoring best model from epoch 96.\n",
      "CPU times: user 2min 49s, sys: 215 ms, total: 2min 49s\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TabSRA = TabSRALinearRegressor(**other_params,callbacks=call_b)\n",
    "_ = TabSRA.fit(X_train_.astype(np.float32),Y_train_.reshape(-1,1).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91820789-6fd2-43b6-b330-64181bb744c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.001876</td>\n",
       "      <td>-4.996838</td>\n",
       "      <td>5.169649</td>\n",
       "      <td>-5.016213</td>\n",
       "      <td>5.380935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5\n",
       "0  5.001876 -4.996838  5.169649 -5.016213  5.380935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coef  = pd.DataFrame(TabSRA.get_weights()[0])\n",
    "Coef.columns=feature_names\n",
    "Coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2922945-2e46-4d59-8bb7-2f3048631b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--RMSE  = 0.3034210188095153 -- r2  = 0.9981866874934777\n"
     ]
    }
   ],
   "source": [
    "pred_tabsra = TabSRA.predict(X_test_.astype(np.float32))\n",
    "\n",
    "rmse_tabsra = np.sqrt(mean_squared_error(Y_test_, pred_tabsra))\n",
    "r2_tabsra = r2_score(Y_test_, pred_tabsra) \n",
    "print(f\"--RMSE  = {rmse_tabsra} -- r2  = {r2_tabsra}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7445d44-6db1-4c0c-bd0c-9df8d4714625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b378d20-a6f1-4935-9c78-ca18ad154565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 ms, sys: 0 ns, total: 28.5 ms\n",
      "Wall time: 5.43 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "attributions_tabsra = pd.DataFrame(TabSRA.get_feature_attribution(X_test_.astype(np.float32)))\n",
    "attributions_tabsra.columns = feature_names\n",
    "attributions_tabsra['pred_proba'] = pred_tabsra\n",
    "attributions_tabsra['label'] = Y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8b426ff-12c9-4d5f-a786-1c1b1f45e505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.768471e-06</td>\n",
       "      <td>0.027804</td>\n",
       "      <td>8.204901e+00</td>\n",
       "      <td>-3.011704e+00</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>5.230494</td>\n",
       "      <td>5.207175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.296751e+00</td>\n",
       "      <td>1.677891</td>\n",
       "      <td>-4.941949e-08</td>\n",
       "      <td>-1.649862e-06</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>3.974492</td>\n",
       "      <td>3.974853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.641793e+00</td>\n",
       "      <td>-0.204040</td>\n",
       "      <td>-6.330068e-09</td>\n",
       "      <td>1.415404e-09</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>1.437385</td>\n",
       "      <td>1.437009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.454783e+00</td>\n",
       "      <td>-9.539963</td>\n",
       "      <td>-5.557716e-05</td>\n",
       "      <td>-9.707033e-04</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>-13.999731</td>\n",
       "      <td>-14.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.808094e-07</td>\n",
       "      <td>-0.013421</td>\n",
       "      <td>2.677278e-01</td>\n",
       "      <td>5.371353e-01</td>\n",
       "      <td>0.044899</td>\n",
       "      <td>0.836339</td>\n",
       "      <td>0.807119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2            x3            x4        x5  pred_proba  \\\n",
       "0 -7.768471e-06  0.027804  8.204901e+00 -3.011704e+00  0.009502    5.230494   \n",
       "1  2.296751e+00  1.677891 -4.941949e-08 -1.649862e-06 -0.000148    3.974492   \n",
       "2  1.641793e+00 -0.204040 -6.330068e-09  1.415404e-09 -0.000368    1.437385   \n",
       "3 -4.454783e+00 -9.539963 -5.557716e-05 -9.707033e-04 -0.003960  -13.999731   \n",
       "4 -9.808094e-07 -0.013421  2.677278e-01  5.371353e-01  0.044899    0.836339   \n",
       "\n",
       "       label  \n",
       "0   5.207175  \n",
       "1   3.974853  \n",
       "2   1.437009  \n",
       "3 -14.000517  \n",
       "4   0.807119  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_tabsra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628816e9-6cc6-4b2d-b846-6db42444d498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58750357-c400-4320-8fdb-c85cd922cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.2 ms, sys: 0 ns, total: 33.2 ms\n",
      "Wall time: 7.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "attention_tabsra = pd.DataFrame(TabSRA.get_attention(X_test_.astype(np.float32))[0])\n",
    "attention_tabsra.columns = feature_names\n",
    "attention_tabsra['pred_proba'] = pred_tabsra\n",
    "attention_tabsra['label'] = Y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "106a92f1-f1c8-4ba8-bee4-fc4231f76e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.521361e-06</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>9.666835e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>5.230494</td>\n",
       "      <td>5.207175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999952e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.758221e-08</td>\n",
       "      <td>2.596590e-07</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3.974492</td>\n",
       "      <td>3.974853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.321437e-10</td>\n",
       "      <td>4.146849e-09</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.437385</td>\n",
       "      <td>1.437009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.997753e-01</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>8.022116e-04</td>\n",
       "      <td>2.500543e-04</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>-13.999731</td>\n",
       "      <td>-14.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.277387e-07</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>9.529745e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.836339</td>\n",
       "      <td>0.807119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2            x3            x4        x5  pred_proba  \\\n",
       "0  2.521361e-06  0.006143  9.666835e-01  9.999999e-01  0.002266    5.230494   \n",
       "1  9.999952e-01  1.000000  2.758221e-08  2.596590e-07  0.000016    3.974492   \n",
       "2  9.999999e-01  1.000000  4.321437e-10  4.146849e-09  0.000046    1.437385   \n",
       "3  9.997753e-01  0.999958  8.022116e-04  2.500543e-04  0.001725  -13.999731   \n",
       "4  2.277387e-07  0.011819  9.529745e-01  1.000000e+00  0.008292    0.836339   \n",
       "\n",
       "       label  \n",
       "0   5.207175  \n",
       "1   3.974853  \n",
       "2   1.437009  \n",
       "3 -14.000517  \n",
       "4   0.807119  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_tabsra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10900ab-ed5d-4f12-9fa9-14ae345f6265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
